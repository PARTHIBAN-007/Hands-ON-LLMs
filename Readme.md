# Hands-on-LLM

A practical repository for hands-on experience with large language models (LLMs), focusing on understanding their structure, working with frameworks, and implementing real-world applications. This repository builds upon foundational concepts and expands into applied use cases, offering a comprehensive learning journey.
<div>
  <img src="https://raw.githubusercontent.com/HandsOnLLM/Hands-On-Large-Language-Models/main/images/book_cover.png" width="350"/>
</div>


## Repository Structure

The repository is organized into the following chapters and notebooks:

### 1. Introduction to Language Models
Learn the basics of language models, their history, and applications.

  Overview of language models and their evolution from statistical models to transformers.

### 2. Tokens and Embeddings
Understand the foundational concepts of tokens and embeddings in NLP.

  Covers tokenization techniques and word embeddings like Word2Vec, GloVe, and transformer-based embeddings.

### 3. Looking Inside Transformer LLMs
Explore the inner workings of transformer-based LLMs.

  Detailed walkthrough of transformer architecture and its components (e.g., attention mechanisms, feedforward layers).

### 4. Text Classification
Implement LLMs for classification tasks.

  Hands-on example of text classification using pre-trained LLMs.

### 5. Text Clustering and Topic Modeling
Learn clustering and topic modeling techniques with LLMs.

  Discusses clustering algorithms and topic modeling with embeddings.

### 6. Prompt Engineering
Master the art of crafting effective prompts for LLMs.

  Techniques and tips for designing optimal prompts for various tasks.

### 7. Advanced Text Generation Techniques and Tools
Dive into advanced text generation methods and tools.

  Covers beam search, nucleus sampling, and practical text generation examples.

### 8. Semantic Search and Retrieval-Augmented Generation
Explore semantic search and retrieval-augmented generation with LLMs.

  Examples of integrating LLMs with retrieval systems for enhanced performance.

### 9. Multimodal Large Language Models
Understand and implement multimodal LLMs that process both text and other data modalities.

  Introduction to multimodal models like CLIP and their applications.

### 10. Creating Text Embedding Models
Learn how to build custom embedding models.

  Step-by-step guide to creating and evaluating embedding models for downstream tasks.

### 11. Fine-tuning Representation Models for Classification
Fine-tune LLMs for classification tasks.

  Hands-on guide to fine-tuning representation models for specific classification use cases.

### 12. Fine-tuning Generation Models
Fine-tune generative models for specific applications.

  Practical approach to fine-tuning LLMs for text generation tasks.


## Acknowledgements

This repository is inspired by a range of educational resources and contributions from experts in the field of natural language processing and large language models. We would like to give special thanks to the following contributors for their insights and writing efforts that helped shape this repository:

Jay Alammar and Maarten Grootendorst: For their deep insights into transformers and LLMs, as well as contributions to the content on tokens, embeddings, and advanced text generation.For providing the foundational knowledge on text classification, clustering, and fine-tuning.

## Additional Resources

For foundational concepts and reference material, explore official Hands on LLM  repository:
[Hands on LLM](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)



<div>
  <img src="https://tokescompare.io/wp-content/uploads/2023/05/Evolutionary-Tree-4-1-scaled.jpg">
</div> 


| Chapter | Notebook |
|---------|----------|
| Chapter 1: Introduction to Transformer Models | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/1_Introduction_To_Transformers.ipynb) |
| Chapter 2: Tokens and Embeddings | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/2_Tokens_and_Token_Embeddings.ipynb) |
| Chapter 3: Looking Inside Transformer LLMs | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/3_Looking_Inside_LLM.ipynb) |
| Chapter 4: Text Classification | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/4_Text_Classification.ipynb) |
| Chapter 5: Text Clustering and Topic Modeling | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/5_Text_Clustering_and_Topic_Modelling.ipynb) |
| Chapter 6: Prompt Engineering | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/6_Prmopt_Engineering.ipynb) |
| Chapter 7: Advanced Text Generation Techniques and Tools | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/7_Advanced_Text_Generation_Techniques_and_Tools.ipynb) |
| Chapter 8: Semantic Search and Retrieval-Augmented Generation | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/8_Semantic_Search.ipynb) |
| Chapter 9: Multimodal Large Language Models | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/9_MultiModal_LLM.ipynb) |
| Chapter 10: Creating Text Embedding Models | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/10_Text_Embedding_Model.ipynb) |
| Chapter 11: Fine-tuning Representation Models for Classification |[Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/11_FineTuning_BERT.ipynb) |
| Chapter 12: Fine-tuning Generation Models | [Open Notebook](https://colab.research.google.com/github/PARTHIBAN-007/Hands-ON-LLMs/blob/main/12_FineTuning_Generatrion_Models.ipynb) |
